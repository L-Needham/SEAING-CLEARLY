{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import skimage as ski\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from skimage import io, exposure, color, restoration, filters, feature, util, metrics, data, img_as_float\n",
    "from natsort import natsorted, ns\n",
    "from inference import get_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "from inference.models.utils import get_roboflow_model\n",
    "from ultralytics import YOLO, settings\n",
    "from functools import partial\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training images from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    images = []\n",
    "    try:\n",
    "        for filename in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                images.append(img)\n",
    "            except IOError as e:\n",
    "                print(f\"Could not open image {img_path}: {e}\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"Permission denied: {e}\")\n",
    "    return images\n",
    "\n",
    "image_path = \"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images\"\n",
    "\n",
    "images = load_images(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply wavelet-based estimator of the Gaussian noise standard deviation. Used for tuning denoising algorithms with the 'sigma' parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import estimate_sigma\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "img = img_as_float(img)\n",
    "\n",
    "sigma_est = np.mean(estimate_sigma(img, channel_axis=-1))\n",
    "print(f\"Estimated noise standard deviation: {sigma_est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply gamma correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "gamma_corrected = exposure.adjust_gamma(img, 2.0)\n",
    "\n",
    "img.mean() > gamma_corrected.mean()\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "# Gamma Corrected\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Gamma Corrected\")\n",
    "plt.imshow(gamma_corrected[:,:,::-1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply local contrast enhancement with Contrast Limited Adaptive Histogram Equalization (CLAHE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import exposure, data, img_as_float\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "img = img_as_float(img)\n",
    "\n",
    "# Apply adaptive histogram equalisation\n",
    "img_equalised = np.zeros_like(img)\n",
    "for i in range(3):\n",
    "    img_equalised[:, :, i] = exposure.equalize_adapthist(img[:, :, i], clip_limit=0.01) # clip_limit is between 0 and 1, higher values increase contrast. \n",
    "\n",
    "# Display the original and equalized images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Equalized Image')\n",
    "plt.imshow(img_equalised[:, :, ::-1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Inferior results compared to gamma correction, requires fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert sRGB to LAB colour space (Luminance (L), and Chromaticity (A/B)).\n",
    "Probably not useful but will leave it incase a use is found, apparently can enable easier colour channel manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert from RGB to LAB\n",
    "lab_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2Lab)\n",
    "\n",
    "plt.imshow(lab_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply non-local denoising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_nl_means\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "img = img_as_float(img)\n",
    "\n",
    "# Apply Non-Local Means denoising\n",
    "patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                patch_distance=6)  # 13x13 search area\n",
    "\n",
    "denoised_img = denoise_nl_means(img, h=0.00605, sigma=0.006065078184261036, fast_mode=True, **patch_kw, channel_axis=-1) \n",
    "# A high h value may result in a smoother image with an increase in blur.\n",
    "# For a Gaussian noise of standard deviation sigma, a rule of thumb is to choose the value of h to be sigma of slightly less.\n",
    "\n",
    "# Display the original and denoised images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Denoised Image\")\n",
    "plt.imshow(denoised_img[:, :, ::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a bilateral denoise filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_bilateral\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "# Apply bilateral denoising\n",
    "bilateral_denoised_img = denoise_bilateral(img, sigma_color=0.05, sigma_spatial=15, bins=10000, channel_axis=-1)\n",
    "\n",
    "# Display the original and bilateral denoised images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Bilateral Denoised Image\")\n",
    "plt.imshow(bilateral_denoised_img[:, :, ::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply unsupervised Wiener-Hunt deconvolution. Does not produce a great result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import unsupervised_wiener\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "img = img_as_float(img)\n",
    "\n",
    "# Define the Point Spread Function (PSF)\n",
    "psf = np.ones((5, 5)) / 25\n",
    "\n",
    "# Apply Unsupervised Wiener deconvolution to each channel separately\n",
    "deconvolved_img = np.zeros_like(img)\n",
    "for i in range(3):\n",
    "    deconvolved_img[:, :, i], _ = unsupervised_wiener(img[:, :, i], psf)\n",
    "\n",
    "# Display the original and deconvolved images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Unsupervised Wiener Deconvolved Image\")\n",
    "plt.imshow(deconvolved_img[:, :, ::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Richardson-Lucy deconvolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import richardson_lucy\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "img = img_as_float(img)\n",
    "\n",
    "deconvolved = np.zeros_like(img)\n",
    "for i in range(3):  # Apply deconvolution on each channel separately\n",
    "    deconvolved[:, :, i] = richardson_lucy(img[:, :, i], psf, num_iter=30)\n",
    "\n",
    "# Display the original and deconvolved images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Deconvolved Image\")\n",
    "plt.imshow(deconvolved[:, :, ::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply rescale of intensity levels to improve contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "rescaled_img = exposure.rescale_intensity(img, in_range='image', out_range=(0, 1)) # Change out_range to adjust exposure.\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Rescaled Intensity Image\")\n",
    "plt.imshow(rescaled_img[:, :, ::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply histogram equalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "equalized_img = exposure.equalize_hist(img)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Histogram Equalized Image\")\n",
    "plt.imshow(equalized_img[:, :, ::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Sobel filter for edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import sobel\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "# Apply Sobel filter for edge detection\n",
    "edges = sobel(img)\n",
    "\n",
    "# Display the original and edge-detected images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Sobel Edge Detection\")\n",
    "plt.imshow(edges, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Scharr transform to find edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import scharr\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "# Apply Scharr filter for edge detection\n",
    "scharr_edges = scharr(img)\n",
    "\n",
    "# Display the original and Scharr edge-detected images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Scharr Edge Detection\")\n",
    "plt.imshow(scharr_edges, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Canny algorithm for edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import canny\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_edges = canny(gray_img, sigma=0.006065078184261036)\n",
    "\n",
    "# Display the original and Canny edge-detected images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Canny Edge Detection\")\n",
    "plt.imshow(canny_edges, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Simple Linear Iterative Clustering (SLIC) for image segmentation. Not sure how to make this work/be of use. Will need to do more testing/research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "\n",
    "# Apply SLIC segmentation\n",
    "segments = slic(img, n_segments=100, compactness=10, sigma=0.006065078184261036, channel_axis=-1, start_label=1)\n",
    "\n",
    "# Display the segmented image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"SLIC Segmentation\")\n",
    "plt.imshow(segments)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is for testing super resolution and Sci-kit image enhancements. Run the above stuff separate from this or change variable names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement OpenCV2 Super Resolution. You have to download each model, this link in useful https://jeanvitor.com/how-use-opencv-superresolution-sr/.\n",
    "EDSR_x4 provides the best results but is much slower and produces the largest file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/0XO5VK05V8L8_jpg.rf.feffd9cb51dd4643f3bbf2174b8adb7d.jpg\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.show()\n",
    "\n",
    "#Create the SR model\n",
    "sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "path = \"EDSR_x4.pb\" # Replace with name of SR model to use eg. EDSR_x2.pb, ESPCN_x4.pb\n",
    "sr.readModel(path)\n",
    "sr.setModel(\"edsr\", 4) # Replace string with name of SR model eg. edsr, espcn, fsrcnn, lapsrn\n",
    "\n",
    "# Upscale the image\n",
    "start = time.time()\n",
    "sr_result = sr.upsample(img)\n",
    " \n",
    "# Resized image\n",
    "resized = cv2.resize(img,dsize=None,fx=4,fy=4)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1,3,1)\n",
    "\n",
    "# Original image\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.subplot(1,3,2)\n",
    "\n",
    "# SR upscaled\n",
    "plt.title(\"SR Upscaled\")\n",
    "plt.imshow(sr_result[:,:,::-1])\n",
    "plt.subplot(1,3,3)\n",
    "\n",
    "# OpenCV upscaled\n",
    "plt.title(\"OpenCV Upscaled\")\n",
    "plt.imshow(resized[:,:,::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Richardson-Lucy deconvolution to the upscaled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "from skimage.restoration import richardson_lucy\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_float\n",
    "\n",
    "# Convert input image to float\n",
    "sr_result = img_as_float(sr_result)\n",
    "\n",
    "# Define the Point Spread Function (PSF) for Richardson-Lucy deconvolution\n",
    "psf = np.ones((5, 5)) / 25\n",
    "\n",
    "# Apply Richardson-Lucy deconvolution\n",
    "deconvolved = np.zeros_like(sr_result)\n",
    "for i in range(3):  # Apply deconvolution on each channel separately\n",
    "    deconvolved[:, :, i] = richardson_lucy(sr_result[:, :, i], psf, num_iter=30)\n",
    "\n",
    "# Display the original and deconvolved images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Deconvolved Image\")\n",
    "plt.imshow(deconvolved[:,:,::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load labels from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(folder):\n",
    "    labels = {}\n",
    "    try:\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                label_path = os.path.join(folder, filename)\n",
    "                with open(label_path, 'r') as file:\n",
    "                    label_data = file.readlines()\n",
    "                    labels[filename] = [line.strip() for line in label_data]\n",
    "    except PermissionError as e:\n",
    "        print(f\"Permission denied: {e}\")\n",
    "    return labels\n",
    "\n",
    "label_path = \"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/labels\"\n",
    "labels = load_labels(label_path)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup/Check Ultralytics and set correct directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(settings)\n",
    "\n",
    "value = settings[\"runs_dir\"]\n",
    "settings.update({\"datasets_dir\": \"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Roboflow pre-trained dataset \"Underwater Marine Species Computer Vision Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own image path to any arbitrary image. It currently only loads one image so we need to figure out how to load all images.\n",
    "image_path = \"C:/Users/needh/OneDrive/Documents/Uni/2024/Sem_2_2024/ICT342/SEAING/Training Images/Underwater Marine Species.v6-marinedataset_v5.yolov8/train/images/288856187_d1fb57a113_b_jpg.rf.1a861f6bf38998d756e6f76a84b73340.jpg\"\n",
    "\n",
    "# Roboflow model\n",
    "model_name = \"underwater-marine-species\"\n",
    "model_version = \"6\"\n",
    "\n",
    "# Get Roboflow face model (this will fetch the model from Roboflow)\n",
    "model = get_roboflow_model(\n",
    "    model_id=\"{}/{}\".format(model_name, model_version),\n",
    "\n",
    "    #Replace ROBOFLOW_API_KEY with your Roboflow API Key\n",
    "    api_key=\"J7ljP04frhJRcBuovOmD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(image_path)\n",
    "\n",
    "results = model.infer(image=frame,\n",
    "                        confidence=0.5,\n",
    "                        iou_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results[0].predictions:\n",
    "    prediction = results[0].predictions[0]\n",
    "    print(prediction)\n",
    "    \n",
    "    x_center = int(prediction.x)\n",
    "    y_center = int(prediction.y)\n",
    "    width = int(prediction.width)\n",
    "    height = int(prediction.height)\n",
    "\n",
    "    # Calculate top-left and bottom-right corners from center, width, and height\n",
    "    x0 = x_center - width // 2\n",
    "    y0 = y_center - height // 2\n",
    "    x1 = x_center + width // 2\n",
    "    y1 = y_center + height // 2\n",
    "    \n",
    "    # Currently only takes one input text as a label\n",
    "    cv2.rectangle(frame, (x0, y0), (x1, y1), (255,255,0), 10)\n",
    "    cv2.putText(frame, \"fish\", (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display chosen image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image from image path. When we get multiple/all images to be loaded we don't want them all to be rendered simultaneously, so this will need to be modified.\n",
    "cv2.imshow('Image Frame', frame)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
